import os
import json
import requests
from datetime import datetime, timedelta
from bs4 import BeautifulSoup
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import feedparser

# –ó–∞–≥—Ä—É–∑–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞
with open("keywords.txt", "r", encoding="utf-8") as f:
    KEYWORDS = [line.strip() for line in f if line.strip()]

# –í—Ä–µ–º—è - –∏—â–µ–º –∑–∞ –≤—á–µ—Ä–∞
yesterday = (datetime.utcnow() + timedelta(hours=3) - timedelta(days=1)).strftime('%Y-%m-%d')

# –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –≤ Google Sheets
scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
creds_json = os.getenv("GOOGLE_CREDS_JSON")
creds_dict = json.loads(creds_json)
creds = ServiceAccountCredentials.from_json_keyfile_dict(creds_dict, scope)
client = gspread.authorize(creds)
sheet = client.open_by_url("https://docs.google.com/spreadsheets/d/1ar4pf2_6zqmplMAFFuB2BsolhpHh00jFvn5kmigaVlE/edit")
worksheet = sheet.sheet1

# –ü–æ–ª—É—á–∞–µ–º —É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Å—Å—ã–ª–∫–∏ (3-—è –∫–æ–ª–æ–Ω–∫–∞)
existing_records = worksheet.get_all_values()
existing_links = {row[2] for row in existing_records if len(row) > 2 and row[2]}

print(f"üîç –ü–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –∑–∞ {yesterday} –ø–æ {len(KEYWORDS)} –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º...")

# --- –ü–æ–∏—Å–∫ –≤ –Ø–Ω–¥–µ–∫—Å–µ
def search_yandex_news(query):
    url = f"https://yandex.ru/news/search?text={query}&from=day"
    headers = {"User-Agent": "Mozilla/5.0"}
    resp = requests.get(url, headers=headers)
    soup = BeautifulSoup(resp.text, "html.parser")
    results = []
    for item in soup.select("article"):
        title_tag = item.find("h2")
        link_tag = item.find("a")
        if title_tag and link_tag:
            title = title_tag.get_text(strip=True)
            link = link_tag.get("href")
            if link and link.startswith("/news"):
                link = "https://yandex.ru" + link
            results.append((title, link))
    return results

# --- –ü–æ–∏—Å–∫ –≤ Google News
def search_google_news(query):
    url = f"https://news.google.com/rss/search?q={query}"
    feed = feedparser.parse(url)
    results = []
    for entry in feed.entries:
        results.append((entry.title, entry.link))
    return results

# --- –û—Å–Ω–æ–≤–Ω–æ–π –ø–∞—Ä—Å–∏–Ω–≥
found_rows = []
for keyword in KEYWORDS:
    yandex_results = search_yandex_news(keyword)
    google_results = search_google_news(keyword)

    combined = yandex_results + google_results
    new_items = 0

    for title, link in combined:
        if link not in existing_links:
            found_rows.append([yesterday, title, link, "", keyword, "–î–∞"])
            existing_links.add(link)  # –ß—Ç–æ–±—ã –Ω–µ –±—ã–ª–æ –ø–æ–≤—Ç–æ—Ä–æ–≤ –≤ –æ–¥–Ω–æ–º –∑–∞–ø—É—Å–∫–µ
            new_items += 1

    print(f"üî∏ {keyword} ‚Äî –Ω–∞–π–¥–µ–Ω–æ {new_items} –Ω–æ–≤—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ {len(combined)} –≤—Å–µ–≥–æ")

# --- –ó–∞–ø–∏—Å—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
if found_rows:
    print(f"‚úÖ –î–æ–±–∞–≤–ª—è—é {len(found_rows)} —Å—Ç—Ä–æ–∫ –≤ Google Sheets...")
    worksheet.append_rows(found_rows)
    print("‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ.")
else:
    print("‚ö†Ô∏è –ù–æ–≤–æ—Å—Ç–µ–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
    worksheet.append_row([yesterday, "–ù–µ—Ç –Ω–æ–≤–æ—Å—Ç–µ–π –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º", "", "", "", "–ù–µ—Ç"])
